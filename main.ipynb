{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sentiment analysis on tweets related to E-levy.\n",
    "\n",
    "#### This project seems to analyze the general consensus on the introduction of e-levy (electronic levy) charges by the Ghana Government on digital transactions. \n",
    "\n",
    "It uses the ------ NLP model to analyze the sentiments of hundreds of tweets scraped from twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing first libraries <br>\n",
    "<ul>\n",
    "<li>snscrape ---> a scraper for social networking services </li>\n",
    "<li>pandas ---> an open source data analysis and manipulation tool </li> \n",
    "<li>re ---> library for string manipulation</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Innocent\n",
      "[nltk_data]     Anyaele\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Innocent\n",
      "[nltk_data]     Anyaele\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import preprocessor as p\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we build our query here by gathering e-levy related tweets from when it was first announced (2022/09/20)\n",
    "\n",
    "we store our gathered tweets in a csv file -> streams.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeTweets():    \n",
    "    query = '\"e-levy\" lang:en until:2022-09-20 since:2022-05-01 -filter:links'\n",
    "\n",
    "    tweets = []\n",
    "    limit = 500\n",
    "\n",
    "    data = sntwitter.TwitterSearchScraper(query).get_items()\n",
    "    for tweet in data:\n",
    "        if len(tweets) == limit:\n",
    "            break\n",
    "        else:\n",
    "            tweet_text = tweet.content\n",
    "            tweets.append([tweet.id, tweet_text, tweet.date])\n",
    "            \n",
    "    df = pd.DataFrame(tweets, columns=['id', 'Tweet', 'Date'])\n",
    "\n",
    "    df.to_csv('stream.csv', index=False, columns=['id','Tweet','Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tweet containes 500 rows, each row containing the tweet id, tweet content and the tweet date.\n",
    "We print the first 5 tweets\n",
    "We see our tweets, contains a lot of unneccessary data for analysis, so we preprocess it in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n",
      "0    @edburtler @shamimamuslim Notice that Shamima ...\n",
      "1    @edburtler @shamimamuslim QUESTION: \\nWhy was ...\n",
      "2    @FrankOw18664478 @hearttooclean @mandemthe1st ...\n",
      "3    @FrankOw18664478 @hearttooclean @mandemthe1st ...\n",
      "4    @FrankOw18664478 @bra_Kofi__ @hearttooclean @m...\n",
      "Name: Tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('stream.csv')\n",
    "print(df.shape)\n",
    "print(df['Tweet'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing stage involves cleaning up our tweets with a regex function by removing links, tags and whitespaces.\n",
    "\n",
    "We also leverage the NLTK library to remove stop words such as \"and\", \"or\", \"in\"\n",
    "\n",
    "After we print some of our tweets, it looks much more cleaner than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495    minister communication ursulaow mocghana moigo...\n",
      "496    georgekankambo4 hmmm tear even cedis elevy npp...\n",
      "497    vodafoneghana charged elevy transaction less c...\n",
      "498                            citi973 like refund elevy\n",
      "499                    everytime pay elevy dey feel sick\n",
      "Name: Tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def tweet_preprocessing(tweet):\n",
    "    # regex cleanup\n",
    "    tweet = re.sub(r\"^https://t.co/[A-Za-z0-9]*\\s\", \" \", tweet)\n",
    "    tweet = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*\\s\", \" \", tweet)\n",
    "    tweet = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*$\", \" \", tweet)\n",
    "    tweet = re.sub(\"\\.\\.+\", \" \", tweet)\n",
    "    tweet = re.sub(\"-$\", \"\", tweet)\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    tweet = re.sub(r\"^ +\", \"\", tweet)\n",
    "    tweet = re.sub(r\"  +\", \" \", tweet)\n",
    "    \n",
    "    # use preprocessing library to clean\n",
    "    tweet = p.clean(tweet)\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # tokenize\n",
    "    token_tweet = word_tokenize(tweet)\n",
    "    filtered = [w for w in token_tweet if not w.lower() in stop_words]\n",
    "    filtered_array  = []\n",
    "    \n",
    "    # remove stopwords\n",
    "    for w in token_tweet:\n",
    "        if w not in stop_words:\n",
    "            filtered_array.append(w)\n",
    "                 \n",
    "    \n",
    "    return ' '.join(filtered_array)\n",
    "\n",
    "\n",
    "# applying our pre processing function to our tweet\n",
    "df['Tweet'] = df['Tweet'].apply(lambda x: tweet_preprocessing(x))\n",
    "print (df['Tweet'].tail(5)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the BERT Model\n",
    "\n",
    "The BERT Model is a transformer based machine learning technique for natural language processing pre-training developed by Google. -> Wikipedia\n",
    "\n",
    "We import the AutoTokenizer and the AutoModel for Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 39.0/39.0 [00:00<00:00, 18.7kB/s]\n",
      "Downloading: 100%|██████████| 953/953 [00:00<00:00, 144kB/s]\n",
      "Downloading: 100%|██████████| 851k/851k [00:18<00:00, 46.3kB/s] \n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 113kB/s]\n",
      "Downloading: 100%|██████████| 638M/638M [20:59<00:00, 531kB/s]    \n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import Torch (an open source machine learning framework that can be used for natural language processing) and create a function that will leverage our tokenizer and model to find the sentiment score of a particular tweet. The score will return an array of scores will be computed on using torch.argmax function to find the appropriate sentiment score.\n",
    "\n",
    "The score will fall in the range 1 - 3.\n",
    "1 being negative sentiment and 3 being position sentiment with 2 a neutral sentiment.\n",
    "\n",
    "Let's try this function on the text \"I hate this\" to test our model.\n",
    "\n",
    "It returns 1 (a negative sentiment).\n",
    "\n",
    "We try function on the text \"I love this\".\n",
    "\n",
    "It returns a 3 (a positive sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def sentiment_score(tweet):\n",
    "    tokens = tokenizer.encode(tweet, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    result.logits\n",
    "    # print (result.logits)\n",
    "    return (int(torch.argmax(result.logits))+1)\n",
    "\n",
    "sentiment_score('I hate this')\n",
    "# sentiment_score('i love this')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply our sentiment score function on a newly created column called sentiment score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_score'] = df['Tweet'].apply(lambda x: sentiment_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1567781340363345920</td>\n",
       "      <td>sikanikwame_ gramof ursula stubborn academy cs...</td>\n",
       "      <td>2022-09-08 07:46:14+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1567773778842718209</td>\n",
       "      <td>kevinekowtaylor nakufoaddo happens elevy cst e...</td>\n",
       "      <td>2022-09-08 07:16:11+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1567756517788598273</td>\n",
       "      <td>elevy affects transactions less gh</td>\n",
       "      <td>2022-09-08 06:07:36+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1567685541897928706</td>\n",
       "      <td>_lawslaw get elevy</td>\n",
       "      <td>2022-09-08 01:25:34+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1567664697737969665</td>\n",
       "      <td>everything e npp successfully implemented elev...</td>\n",
       "      <td>2022-09-08 00:02:44+00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1567652269893500929</td>\n",
       "      <td>minister communication ursulaow mocghana moigo...</td>\n",
       "      <td>2022-09-07 23:13:21+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1567649835804663809</td>\n",
       "      <td>georgekankambo4 hmmm tear even cedis elevy npp...</td>\n",
       "      <td>2022-09-07 23:03:41+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1567630086681108482</td>\n",
       "      <td>vodafoneghana charged elevy transaction less c...</td>\n",
       "      <td>2022-09-07 21:45:12+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1567607475356012545</td>\n",
       "      <td>citi973 like refund elevy</td>\n",
       "      <td>2022-09-07 20:15:21+00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1567605853531897859</td>\n",
       "      <td>everytime pay elevy dey feel sick</td>\n",
       "      <td>2022-09-07 20:08:54+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                              Tweet  \\\n",
       "490  1567781340363345920  sikanikwame_ gramof ursula stubborn academy cs...   \n",
       "491  1567773778842718209  kevinekowtaylor nakufoaddo happens elevy cst e...   \n",
       "492  1567756517788598273                 elevy affects transactions less gh   \n",
       "493  1567685541897928706                                 _lawslaw get elevy   \n",
       "494  1567664697737969665  everything e npp successfully implemented elev...   \n",
       "495  1567652269893500929  minister communication ursulaow mocghana moigo...   \n",
       "496  1567649835804663809  georgekankambo4 hmmm tear even cedis elevy npp...   \n",
       "497  1567630086681108482  vodafoneghana charged elevy transaction less c...   \n",
       "498  1567607475356012545                          citi973 like refund elevy   \n",
       "499  1567605853531897859                  everytime pay elevy dey feel sick   \n",
       "\n",
       "                          Date  sentiment_score  \n",
       "490  2022-09-08 07:46:14+00:00                2  \n",
       "491  2022-09-08 07:16:11+00:00                2  \n",
       "492  2022-09-08 06:07:36+00:00                2  \n",
       "493  2022-09-08 01:25:34+00:00                2  \n",
       "494  2022-09-08 00:02:44+00:00                3  \n",
       "495  2022-09-07 23:13:21+00:00                1  \n",
       "496  2022-09-07 23:03:41+00:00                2  \n",
       "497  2022-09-07 21:45:12+00:00                2  \n",
       "498  2022-09-07 20:15:21+00:00                2  \n",
       "499  2022-09-07 20:08:54+00:00                1  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean       1.810000\n",
       "std        0.488238\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        2.000000\n",
       "75%        2.000000\n",
       "max        3.000000\n",
       "Name: sentiment_score, dtype: float64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a newly created column with the text equivalent of our score.\n",
    "1 - negative\n",
    "2 - neutral\n",
    "3 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490     Neutral\n",
       "491     Neutral\n",
       "492     Neutral\n",
       "493     Neutral\n",
       "494    Positive\n",
       "495    Negative\n",
       "496     Neutral\n",
       "497     Neutral\n",
       "498     Neutral\n",
       "499    Negative\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment(x):\n",
    "    if x == 1:\n",
    "        return 'Negative'\n",
    "    if x == 2:\n",
    "        return 'Neutral'\n",
    "    if x == 3:\n",
    "        return \"Positive\"\n",
    "    \n",
    "df['sentiment'] = df['sentiment_score'].apply(lambda x: get_sentiment(x))\n",
    "\n",
    "df['sentiment'].tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
